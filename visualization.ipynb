{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a6248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import easydict\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from helper import load_model\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a70adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"simple\": False,\n",
    "    \"bins\": 36, 'act':'linear',\n",
    "    'backbone' : 'DepthHistB', \n",
    "    'path_pretrained' : \"./Models/pretrained/swin_base_patch4_window7_224_22k.pth\",\n",
    "    'path_pth_model' : './checkpoints/NYUv2/model_kitti_cauchy.pt',\n",
    "    'kernel':'cauchy',})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d841cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10566705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(x):\n",
    "    mean = torch.Tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(x.device)\n",
    "    std = torch.Tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(x.device)\n",
    "    return x * std + mean\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Load an image, apply necessary transformations including normalization,\n",
    "    and return a tensor ready for model inference.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Preprocessed image tensor ready for model input.\n",
    "    \"\"\"\n",
    "    # Load the image and ensure it's in RGB format\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Convert the image to a NumPy array and scale pixel values to [0, 1]\n",
    "    image_np = np.array(image).astype(np.float32) / 255.0\n",
    "\n",
    "    # Convert to torch tensor\n",
    "    image_tensor = torch.from_numpy(image_np)\n",
    "    image_tensor = image_tensor.permute(2, 0, 1)\n",
    "\n",
    "    # Apply normalization\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    image_tensor = normalize(image_tensor)\n",
    "\n",
    "\n",
    "    # Add batch dimension\n",
    "    return image_tensor.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60216a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_images(input_image, output_image_1):\n",
    "    \"\"\"\n",
    "    Plots the input and output images.\n",
    "    \n",
    "    Parameters:\n",
    "    input_image (torch tensor): Input image of shape (1, 3, H, W)\n",
    "    output_image (torch tensor): Output image of shape (1, 1, H, W)\n",
    "    \"\"\"\n",
    "    # Convert torch tensors to numpy arrays\n",
    "    input_image_np  = input_image.squeeze(0).permute(1, 2, 0).detach().numpy()\n",
    "    output_image_np_1 = output_image_1.squeeze(0).squeeze(0).detach().cpu().numpy()\n",
    "    # Plot the input image\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(input_image_np.astype(np.uint8))\n",
    "    plt.title(\"RGB image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot the output image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(output_image_np_1, cmap='magma_r')\n",
    "    plt.title(\"Depth map\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae1412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess_image(\"/home/rcam/Pictures/Results/0000000005.png\")\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76127ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(image)\n",
    "pred = F.interpolate(pred[0], image.shape[2:])\n",
    "plot_images(denormalize(image)*255, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602982c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DepthHist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
